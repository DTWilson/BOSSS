---
title: "Examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

```{r setup, eval=TRUE}
library(BOSSS)
library(here)
library(reshape2)
library(msm)
```

In this vignette we provide a few example applications of BOSSS.

## NIFTy

The NIFTy trial was open to people having total thyroid surgery and aimed to find out whether using near-infrared fluorescence imaging could reduce the number of people whose parathyroid glands become damaged during thyroid surgery. It was an adaptive design with an interim analysis based on a (binary) short-term outcome, and a final analysis based on a (again, binary) long-term outcome.

The design problem here is to choose the sample size and the decision rule for both the inerim and final analysis. Both analyses used a $\chi^2$ test, so the decision rule could be expressed as the nominal $\alpha$ used at each stage.

This is the simulation function, exactly as provided by the trial statistician except for small adjustments to the arguments and return values to conform to the BOSSS standards.

```{r}
#n is the total sample size
#ninterim is the number of patients at the interim analysis (proportion)
#ainterim is alpha at interim analysis (threshold p-value at interim analysis)
#afinal is alpha at final analaysis (threshold p-value for 2nd and final analysis)
#this means overall alpha for the trial is ainterim*afinal
#
#pcontshort is the probability of 1 day PoSH in the control arm
#pexpshort is the probability of 1 day PoSH in the experimental arm
#pcontlong is the probability of 6 month PoSH in the control arm
#pexplong is the probability of 6 month PoSH in the experimental arm
#p01_relative is s.t. p01_relative*pexplong = probability of having 
# a long term outcome after no short term outcome

sim_trial <- function(design = list(n = 300, ninterim = 0.5, ainterim = 0.4, afinal = 0.1),
                      hypothesis = list(pcontshort = 0.25, pexpshort = 0.125,
                      pcontlong = 0.1, pexplong = 0.03, p01_relative = 0))
{
  n <- design[[1]]; ninterim <- design[[2]]
  ainterim <- design[[3]]; afinal <- design[[4]]
  
  pcontshort <- hypothesis[[1]]; pexpshort <- hypothesis[[2]]
  pcontlong <- hypothesis[[3]]; pexplong <- hypothesis[[4]]; p01_relative <- hypothesis[[5]]
  
  ninterim <- floor(ninterim*n)
  
  patients<-c(1:n) #create patients
  
  treat<- rep(c(1,2), ceiling(n/2))[1:n]
  
  n_cont <- sum(treat == 1)
  
  short<-rep(0,n) #short term outcome
  long<-rep(0,n) #long term outcome
  
  data<-data.frame(patients,treat,short,long) #combine into dataset
  
  #generate result 1/0 for short term outcome. If short term outcome=0 then long term outcome=0
  #If short term outcome=1 then long term outcome has probability pcontlong/pcontshort
  #repeat for treatment=2
  # for(i in 1:n){
  #   if(treat[i]==1){
  #     data$short[i]<-rbinom(1,1,pcontshort)
  #     if(data$short[i]==0){
  #       data$long[i]<-0
  #     }
  #     if(data$short[i]==1){
  #       data$long[i]<-rbinom(1,1,pcontlong/pcontshort)
  #     }
  #   }
  #   else{
  #     data$short[i]<-rbinom(1,1,pexpshort)
  #     if(data$short[i]==0){
  #       data$long[i]<-0
  #     }
  #     if(data$short[i]==1){
  #       data$long[i]<-rbinom(1,1,pexplong/pexpshort)
  #     }
  #   }
  # }
  
  # An alternative and more general parametersation of the above model
  # to allow different values of probability of a long outcome after
  # no short outcome (previously hard coded as 0)

  # probability vector p00, p01, p10, p11 in (short, long) form
  # Control arm:
  p01 <- p01_relative*pcontlong
  p11 <- pcontlong - p01
  p10 <- pcontshort - p11
  # Simulate outcomes in multinomial format
  cont_count <- rmultinom(1, n_cont, c((1 - p01 - p10 - p11), p01, p10, p11))
  # Translate these to short and long outcomes
  cont_out <- matrix(c(rep(c(0,0), cont_count[1]),
                       rep(c(0,1), cont_count[2]),
                       rep(c(1,0), cont_count[3]),
                       rep(c(1,1), cont_count[4])), ncol = 2, byrow = TRUE)
  # shuffle the list randomly
  cont_out <- cont_out[sample(1:nrow(cont_out)),]
  
  # Experimental arm:
    # Control arm:
  p01 <- p01_relative*pexplong
  p11 <- pexplong - p01
  p10 <- pexpshort - p11
  exp_count <- rmultinom(1, n - n_cont, c((1 - p01 - p10 - p11), p01, p10, p11))
  exp_out <- matrix(c(rep(c(0,0), exp_count[1]),
                       rep(c(0,1), exp_count[2]),
                       rep(c(1,0), exp_count[3]),
                       rep(c(1,1), exp_count[4])), ncol = 2, byrow = TRUE)
  exp_out <- exp_out[sample(1:nrow(exp_out)),]
  
  data[data$treat == 1, c("short", "long")] <- cont_out
  data[data$treat == 2, c("short", "long")] <- exp_out
  
  #perform chi squared test on short term outcome for 1st ninterim patients
  data2<-data[1:ninterim,]
  tbl<-table(data2$short,data2$treat)
  test<- suppressWarnings(chisq.test(tbl)$p.value) #get p-value
  
  #if p<ainterim, perform chi squared test on long term outcome for all patients
  if(test<ainterim){
    tbl2<-table(data$long,data$treat)
    test2<- suppressWarnings(chisq.test(tbl2)$p.value)
  }
  
  #if p>ainterim, trial unsuccessful at interim and final analysis
  #if p<ainterim, trial successful at interim:
  #if p2>afinal, trial unsuccessful at final analysis
  #if p2<afinal, trial successful at final analysis
  if(test>=ainterim){
    return(c(g = FALSE, s = TRUE, n = ninterim))
  }
  if(test<ainterim){
    if(mean(data2[data2$treat == 1,"short"]) < mean(data2[data2$treat == 2,"short"])){
      return(c(g = FALSE, s = TRUE, n = ninterim))
    } else {
      if(test2>afinal){
        return(c(g = FALSE, s = TRUE, n = n))
      }
      if(test2<afinal){
        return(c(g = TRUE, s = FALSE, n = n))
      }
    }
  }
}

# For example,
sim_trial()
```
We can construct the BOSSS problem object as follows:

```{r}
# Problem specification
design_space <- design_space(lower = c(300,0.05,0,0), 
                             upper = c(700,0.5,1,1),
                             sim = sim_trial)

hypotheses <- hypotheses(values = matrix(c(0.25, 0.25, 0.1, 0.1, 0, 
                                           0.25, 0.125, 0.1, 0.03, 0), ncol = 2),
                         hyp_names = c("null", "alt"),
                         sim = sim_trial)

constraints <- constraints(name = c("TI_con", "TII_con"),
                   out = c("g", "s"),
                   hyp = c("null", "alt"),
                   nom = c(0.1, 0.2),
                   delta =c(0.95, 0.95),
                   binary = c(TRUE, TRUE))

objectives <- objectives(name = c("TI", "TII", "EN"),
                 out = c("g", "s", "n"),
                 hyp = c("null", "alt", "null"),
                 weight = c(100, 100, 1),
                 binary = c(TRUE, TRUE, FALSE))

prob <- BOSSS_problem(sim_trial, design_space, hypotheses, objectives, constraints)
```

This implies we are going to search over a space of sample sizes and decision criteria, looking for trial designs which simultaneously minimise the type I error rate (`"TI"`), type II error rate (`"TII"`) and expected sample size (`"EN"`), subject to the type I error rate being (probably) less than 0.1 (`"TI_con"`) and the type II error rate being (probably) less than 0.2 (`"TIIcon"`).

Now we initialise to get an initial estimate of the Pareto front:

```{r}
set.seed(987953021)

# Initialisation
size <- 40
N <- 500

ptm <- proc.time()
sol <- BOSSS_solution(size, N, prob)
proc.time() - ptm
```

```{r, include = FALSE, eval=TRUE}
# Save problems and initial solution
p <- here("vignettes", "example_files", "NIFTy_prob.rds")
#saveRDS(prob, p)
prob <- readRDS(p)

p <- here("vignettes", "example_files", "NIFTy_sol_init.rds")
#saveRDS(sol, p)
sol <- readRDS(p)
```

```{r, eval = TRUE}
print(sol) 
plot(sol)
```

Finally, we iterate a few times to improve that initial approximation:

```{r}
# Iterations
ptm <- proc.time()
N <- 500
for(i in 1:20) {
  sol <- iterate(sol, prob, N) 
}
proc.time() - ptm
```

```{r, include = FALSE, eval=TRUE}
# Save problems and initial solution
p <- here("vignettes", "example_files", "NIFTy_sol_final.rds")
#saveRDS(sol, p)
sol <- readRDS(p)
```

```{r, eval=TRUE}
print(sol)

p <- PS_empirical_ests(sol, prob)[[1]][, c(1,3,5)]
p[,1] <- 1/(1 + exp(-p[,1]))
p[,2] <- 1/(1 + exp(-p[,2]))

df <- cbind(sol$p_set[,1:4], p)

df <- df[order(df[,1]),]
  
colnames(df) <- c("$n$", "$n_{int}$", "$\\alpha_{int}$", "$\\alpha_{f}$",
                       "$E[g ~|~ H_0]$", "$E[s ~|~ H_1]$", "$E[N ~|~ H_0]$")

#print(xtable(df, digits = c(0,0,2,2,2,2,2,0)), booktabs = T, include.rownames = T, sanitize.text.function = function(x) {x}, floating = F, file = here("man", "tables", "NIFTy.txt"))

plot(sol)

#ggsave(here("man", "figures", "NIFTy.pdf"), height=9, width=14, units="cm")
```

From this set of efficient solutions, suppose we judge number 49 to offer the best trade-offs. Checking that design gives:

```{r}
design <- sol$p_set[row.names(sol$p_set) == 49,]

r <- diag_check_point(design, prob, sol, N=10^5) 

# Model 1 prediction interval: [0.052, 0.066]
# Model 1 empirical interval: [0.06, 0.063]

# Model 2 prediction interval: [0.101, 0.13]
# Model 2 empirical interval: [0.109, 0.113]

# Model 3 prediction interval: [224.613, 233.95]
# Model 3 empirical interval: [230.007, 231.58]
```

This confirms that this specific design is well within our two constraints, and also suggests the three GP models are fitting the simulated data well.

## PRESSURE 2

PRESSURE 2 was a trial comparing different mattresses in terms of their ability to prevent the development of pressure ulcers, with longitudinal data collected on each patient. Smith et al. (2021) suggested one way to analyse this data is through a multi-state model, and showed how simulation could be used to estimate the power of such an analysis. Herw we will extend this approach to searching for an optimal design.

The simulation and deterministic functions are:

```{r}
sim_P2 <- function(design = list(n = 500, fu = 60, af = 1), 
                   hypothesis = list(q12 = 0.05, q23 = 0.05, q34 = 0.03, 
                                     b12 = 0.67, b23 = 0.67, b34 = 0.67)){
  
  # n: total number of patients
  # fu: follow-up length (days)
  # af: assemment frequency (days)
  # q12, q23, q34: transition probabilities
  # b12, b23, b34: treatment effects
  
  n <- design[[1]]; fu <- design[[2]]; af <- design[[3]]
  q12 <- hypothesis[[1]]; q23 <- hypothesis[[2]]; q34 <- hypothesis[[3]] 
  b12 <- hypothesis[[4]]; b23 <- hypothesis[[5]]; b34 <- hypothesis[[6]]
  
  # Calculate length of follow up
  na <- n*floor(fu/af)
  
  # Assessment times
  as_times <- floor(seq(af, fu, af))
  
  # Simulate numbers starting in each state
  starts <- rep(1:3, times = rmultinom(1, n, c(0.15, 0.7, 0.15)))
  # Randomly allocate treatment
  trt <- rbinom(n, 1, 0.5)
  
  # Simulate transitions into each remaining state
  enter2 <- (starts == 1)*rexp(n, q12*exp(log(b12)*trt))
  enter3 <- (starts != 3)*(enter2 + rexp(n, q23*exp(log(b23)*trt)))
  enter4 <- (starts != 3)*enter3 + rexp(n, q34*exp(log(b34)*trt))
  
  # Matrix of transition times into each state for each patient
  enter_m <- matrix(c(enter2, enter3, enter4), ncol = 3)
  
  # Add time of "transitioning" to the end of the follow-up period
  enter_m <- cbind(enter_m, pmax(enter_m[,3], fu))
  # Cap all times at length of follow-up
  enter_m <- pmin(enter_m, fu)
  
  # Ceiling all times, assuming assessment is at the start of the day 
  # and so any transitions after x.0 will be seen at (x+1).0
  enter_m <- ceiling(enter_m)
  
  # Translate into number of days spent in each state
  times_m <- cbind(enter_m[,1], 
                   enter_m[,2] - enter_m[,1], 
                   enter_m[,3] - enter_m[,2],
                   enter_m[,4] - enter_m[,3])

  y <- t(apply(times_m, 1, function(x) rep(1:4, times = x)))
  
  # Reshape to long
  y <- melt(y)
  colnames(y) <- c("id", "time", "state")
  y$trt <- trt[y$id]
  
  # Keep observations on assessment times and order by patient
  y <- y[y$time %in% as_times,]
  y <- y[order(y$id),]
  
  Q <- rbind ( c(0, 0.1, 0, 0), 
               c(0, 0, 0.1, 0), 
               c(0, 0, 0, 0.1), 
               c(0, 0, 0, 0) )

  # If msm returns an error we take this as a non-significant result
  suppressWarnings(fit <- try({
    msm(state ~ time, subject=id, data = y, qmatrix = Q,
             covariates = ~ trt)
  }, silent = TRUE))
  
  if (class(fit) == "try-error") {
    sig <- 0
  } else {
    # If not converged, will not return CIs
    r1.67 <- hazard.msm(fit, cl = 1 - 0.0167)$trt
    if(ncol(r1.67) != 3){
      sig <- 0
    } else {
      sig1.67 <- sum(!(r1.67[,2] < 1 & r1.67[,3] > 1)) >= 3
      
      r2.5 <- hazard.msm(fit, cl = 1 - 0.025)$trt
      sig2.5 <- sum(!(r2.5[,2] < 1 & r2.5[,3] > 1)) >= 2
      
      r5 <- hazard.msm(fit, cl = 1 - 0.05)$trt
      sig5 <- sum(!(r5[,2] < 1 & r5[,3] > 1)) >= 1
      
      sig <- any(c(sig1.67, sig2.5, sig5))
    }
  }
  return(c(s = !sig))
}

det_P2 <- function(design = list(n = 500, fu = 60, af = 1), 
                   hypothesis = list(q12 = 0.05, q23 = 0.05, q34 = 0.03, 
                                     b12 = 0.67, b23 = 0.67, b34 = 0.67)){
  
  # n: total number of patients
  # fu: follow-up length (days)
  # af: assemment frequency (days)
  # q12, q23, q34: transition probabilities
  # b12, b23, b34: treatment effects
  
  n <- design[[1]]; fu <- design[[2]]; af <- design[[3]]
  q12 <- hypothesis[[1]]; q23 <- hypothesis[[2]]; q34 <- hypothesis[[3]] 
  b12 <- hypothesis[[4]]; b23 <- hypothesis[[5]]; b34 <- hypothesis[[6]]
  
  na <- n*floor(fu/af)
  
  return(c(n = n, a = na, f = fu))
}

sim_P2()
```

We now construct a problem to encode that we want to search over the total number of patients, total number of assessments and the assessment frequency. We are looking for designs which minimise the numbers of pattens and assessments, whilst constraining the type II error rate to be (probably) less than 0.2 and the follow-up length to be less than 200.

```{r}
design_space <- design_space(lower = c(50, 10, 1), 
                             upper = c(500, 60, 10),
                             sim = sim_P2)

hypotheses <- hypotheses(values = matrix(c(0.05, 0.05, 0.03, 0.67, 0.67, 0.67), ncol = 1),
                         hyp_names = c("alt"),
                         sim = sim_P2)

constraints <- constraints(name = c("a"),
                   out = c("s"),
                   hyp = c("alt"),
                   nom = c(0.2),
                   delta =c(0.95),
                   binary = c(TRUE))

objectives <- objectives(name = c("n", "a", "f"),
                 out = c("n", "a", "f"),
                 hyp = c("alt", "alt", "alt"),
                 weight = c(10, 1, 10),
                 binary = c(FALSE, FALSE, FALSE))

prob <- BOSSS_problem(sim_P2, design_space, hypotheses, objectives, constraints, det_func = det_P2)
```


```{r}
set.seed(327324)

size <- 30
N <- 100

ptm <- proc.time()
sol <- BOSSS_solution(size, N, prob)
proc.time() - ptm
```


```{r, include = FALSE, eval=TRUE}
# Save problems and initial solution
p <- here("vignettes", "example_files", "P2_prob.rds")
#saveRDS(prob, p)
prob <- readRDS(p)

p <- here("vignettes", "example_files", "P2_sol_init.rds")
#saveRDS(sol, p)
sol <- readRDS(p)
```

```{r, eval=TRUE}
print(sol) 
plot(sol)
```

```{r}
N <- 100
ptm <- proc.time()
for(i in 1:20) {
  sol <- iterate(sol, prob, N) 
}
proc.time() - ptm
```

```{r, include = FALSE, eval=TRUE}
# Save problems and initial solution
p <- here("vignettes", "example_files", "P2_sol_final.rds")
#saveRDS(sol, p)
sol <- readRDS(p)
```


```{r, eval=TRUE}
print(sol)

p <- PS_empirical_ests(sol, prob)[[2]][, 1]
p <- 1 - 1/(1 + exp(-p))

df <- sol$p_set[,1:3]
df$a <- (df$fu %/% df$af)*df$n

df <- cbind(df, p)

df <- df[order(df[,1]),]
  
colnames(df) <- c("$n$", "$f$", "$a_f$", "a",
                       "$E[s ~|~ H_1]$")

#print(xtable(df, digits = c(0,0,0,0,0,2)), booktabs = T, include.rownames = T, sanitize.text.function = function(x) {x}, floating = F, file = here("man", "tables", "P2.txt"))

plot(sol)

#ggsave(here("man", "figures", "P2.pdf"), height=9, width=14, units="cm")
```

## Recruitment

Consider a standard two-arm parallel group trial with a continuous endpoint and a t-test of the group means as the planned analysis. Suppose that we are concerned about how well this trial will recruit, and would like to estimate what the overall probability of a significant result will be when we allow for the uncertainty in attained sample size. We can approach this by using a hierarchical Poisson-Gamma model of multi-site recruitment, with site setup times following a Poisson process. To account for the uncertainty around the true parameter values in that recruitment model we take a Bayesian view and give priors for each parameter. This view then also extends to our outcome model, and we place priors on the mean difference and the outcome standard deviation too. 

The design problem here is to choose both the number of recruiting sites and the length of the recruitment period. The model parameters are the hyperparameters of our prior distributions. We want to set a constraint on the unconditional probability of a type II error under the hypothesis of interest, and want to minimise the number of sites and the recruitment period subject to that constraint. We want a simulation function which returns the conditional power (conditioning on the attained sample size and the parameters of the outcome model) for any given design and hypothesis, and a deterministic function to return the two objective functions.

```{r}
library(BOSSS)

sim_rec <- function(design = list(m=20, t=3), 
                    hypothesis = list(a=7, b=2, c=2, d=0.8, 
                                      f=10, g=1,
                                      j=0.3, k=0.3, x=1, y=0.2))
{
  # m - total number of sites to be set up
  # t - time (in years) for recruitment
  # a, b - hyperparameters for rec mean (gamma)
  # c, d - hyperparameters for rec sd (gamma)
  # f, g - hyperparameters for eta (gamma)
  # j, k - hyperparameters for delta (normal)
  # x, y - hyperparameters for sigma (gamma)
  
  m <- design[[1]]; t <- design[[2]]
  
  a <- hypothesis[[1]]; b <- hypothesis[[1]]; c <- hypothesis[[1]]; d <- hypothesis[[1]]
  f <- hypothesis[[1]]; g <- hypothesis[[1]]
  j <- hypothesis[[1]]; k <- hypothesis[[1]]; x <- hypothesis[[1]]; y <- hypothesis[[1]]

  # Sample parameters from their priors
  # Recruitment rate
  alpha <- rgamma(1, (a/b)^2, scale = b^2/a)
  beta <- rgamma(1, (c/d)^2, scale = d^2/c)
  # Setup rate
  eta <- rgamma(1, (f/g)^2, scale = g^2/f)
  # Treatment effect
  delta <- rnorm(1, j, k)
  # Outcome sd
  sigma <- rgamma(1, (x/y)^2, scale = y^2/x)
  
  # True per year recruitment rates for each site
  lambdas <- rgamma(m, alpha, scale=beta)
  
  # Setup times
  setup_ts <- cumsum(rexp(m, eta))
  
  # For each site, simulate number recruited by end
  rec_times <- pmax(t - setup_ts, 0)
  ns <- rpois(m, lambdas*rec_times)
  
  # Total recruited at final
  end_n <- sum(ns)
  
  # Cap at target recruitment
  end_n <- min(end_n, 352)
  
  # Power at analysis
  pow <- power.t.test(n = end_n/2, delta = delta, sd = sigma)$power
  pow
  
  return(c(pr_tII = 1 - pow))
}

det_rec <- function(design = list(m=20, t=3), 
                    hypothesis = list(a=7, b=2, c=2, d=0.8, 
                                      f=10, g=1,
                                      j=0.3, k=0.3, x=1, y=0.2))
{
  m <- design[[1]]; t <- design[[2]]
  
  a <- hypothesis[[1]]; b <- hypothesis[[1]]; c <- hypothesis[[1]]; d <- hypothesis[[1]]
  f <- hypothesis[[1]]; g <- hypothesis[[1]]
  j <- hypothesis[[1]]; k <- hypothesis[[1]]; x <- hypothesis[[1]]; y <- hypothesis[[1]]
  return(c(m = floor(m), t = t))
}


# For example,
sim_rec()
```

Now we set up the problem using the `BOSSS` helper functions. We are going to look at designs with between 3 and 40 sites, running from between 6 months and 5 years.

```{r}
# Problem specification
design_space <- design_space(lower = c(3,0.5), 
                             upper = c(40,5),
                             sim = sim_rec)

hypotheses <- hypotheses(values = matrix(c(7, 2, 2, 0.8, 
                                           10, 1, 0.3, 0.3, 1, 0.2), ncol = 1),
                         hyp_names = c("alt"),
                         sim = sim_rec)

constraints <- constraints(name = c("TII_ass"),
                   out = c("pr_tII"),
                   hyp = c("alt"),
                   nom = c(0.4),
                   delta =c(0.95),
                   binary = c(FALSE))

objectives <- objectives(name = c("Sites", "Time"),
                 out = c("m", "t"),
                 hyp = c( "alt", "alt"),
                 weight = c(1, 10),
                 binary = c(FALSE, FALSE))

prob <- BOSSS_problem(sim_rec, design_space, hypotheses, objectives, constraints, det_func = det_rec)
```

```{r}
size <- 20
N <- 100

sol <- BOSSS_solution(size, N, prob)

print(sol)
plot(sol)
```

```{r}
for(i in 1:30) {
  sol <- iterate(sol, prob, N) 
}

print(sol)
plot(sol)
```

## References

- Croft J, Ainsworth G, Corrigan N, et al. NIFTy: near-infrared fluorescence (NIRF) imaging to prevent postsurgical hypoparathyroidism (PoSH) after thyroid surgery—a phase II/III pragmatic, multicentre randomised controlled trial protocol in patients undergoing a total or completion thyroidectomy. _BMJ Open_, 15:e092422 (2025). https://doi.org/10.1136/bmjopen-2024-092422

- Nixon, Jane et al. Pressure Relieving Support Surfaces for Pressure Ulcer Prevention (PRESSURE 2): Clinical and Health Economic Results of a Randomised Controlled Trial. _eClinicalMedicine_, Volume 14, 42 - 52 (2019)

- Smith IL, Nixon JE, Sharples L. Power and sample size for multistate model analysis of longitudinal discrete outcomes in disease prevention trials. _Statistics in Medicine_, 40: 1960–1971 (2021). https://doi.org/10.1002/sim.8882
